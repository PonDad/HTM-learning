{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hello_tm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__doc__=\"\"\"\n",
    "このプログラムでは、以下のようなデモを行い、Temporal Memoryに直接アクセスする方法を示しています。 TMインスタンスの作成方法、ベクトルを使った学習方法、予測値の取得方法、そして は状態を検査します。\n",
    "\n",
    "このコードはシーケンス学習の非常にシンプルなバージョンを実行しています。 セルをカラムごとに表示します。TM は単純なシーケンス A->B->C->D->E で学習されます。\n",
    "\"\"\"\n",
    "\n",
    "from htm.bindings.sdr import SDR\n",
    "from htm.algorithms import TemporalMemory as TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定の方法でSDRを印刷するためのユーティリティルーチンです\n",
    "def formatBits(sdr):\n",
    "  s = ''\n",
    "  for c in range(sdr.size):\n",
    "    if c > 0 and c % 10 == 0:\n",
    "      s += ' '\n",
    "    s += str(sdr.dense.flatten()[c])\n",
    "  s += ' '\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "################################################################################\n\nこのプログラムでは、以下のようなデモを行い、Temporal Memoryに直接アクセスする方法を示しています。 TMインスタンスの作成方法、ベクトルを使った学習方法、予測値の取得方法、そして は状態を検査します。\n\nこのコードはシーケンス学習の非常にシンプルなバージョンを実行しています。 セルをカラムごとに表示します。TM は単純なシーケンス A->B->C->D->E で学習されます。\n\n################################################################################\n\nCreating the Temporal Memory\n"
    }
   ],
   "source": [
    "def printStateTM( tm ):\n",
    "    # 内部状態をトレースするのに便利\n",
    "    print(\"Active cells     \" + formatBits(tm.getActiveCells()))\n",
    "    print(\"Winner cells     \" + formatBits(tm.getWinnerCells()))\n",
    "    tm.activateDendrites(True)\n",
    "    print(\"Predictive cells \" + formatBits(tm.getPredictiveCells()))\n",
    "    print(\"Anomaly\", tm.anomaly * 100, \"%\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "print(\"################################################################################\")\n",
    "print(__doc__)\n",
    "print(\"################################################################################\")\n",
    "print(\"\")\n",
    "print(\"Creating the Temporal Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Temporal Memory Parameters\nversion                   = 2\nnumColumns                = 50\ncellsPerColumn            = 1\nactivationThreshold       = 8\ninitialPermanence         = 0.5\nconnectedPermanence       = 0.5\nminThreshold              = 8\nmaxNewSynapseCount        = 20\npermanenceIncrement       = 0.1\npermanenceDecrement       = 0\npredictedSegmentDecrement = 0\nmaxSegmentsPerCell        = 255\nmaxSynapsesPerSegment     = 255\n"
    }
   ],
   "source": [
    "tm = TM(columnDimensions = (50,),\n",
    "        cellsPerColumn=1,\n",
    "        initialPermanence=0.5,\n",
    "        connectedPermanence=0.5,\n",
    "        minThreshold=8,\n",
    "        maxNewSynapseCount=20,\n",
    "        permanenceIncrement=0.1,\n",
    "        permanenceDecrement=0.0,\n",
    "        activationThreshold=8,\n",
    "        )\n",
    "tm.printParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nテンポラリメモリに供給する入力を作成します。\n各入力は、アクティブなミニカラムを表します。 \nここでは、5つのシーケンスを表すシンプルなSDRを作成します。\nA -> B -> C -> D -> E  \n"
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "テンポラリメモリに供給する入力を作成します。\n",
    "各入力は、アクティブなミニカラムを表します。 \n",
    "ここでは、5つのシーケンスを表すシンプルなSDRを作成します。\n",
    "A -> B -> C -> D -> E  \"\"\")\n",
    "dataset = { inp : SDR( tm.numberOfColumns() ) for inp in \"ABCDE\" }\n",
    "dataset['A'].dense[0:10]  = 1   # Input SDR representing \"A\", corresponding to mini-columns 0-9\n",
    "dataset['B'].dense[10:20] = 1   # Input SDR representing \"B\", corresponding to mini-columns 10-19\n",
    "dataset['C'].dense[20:30] = 1   # Input SDR representing \"C\", corresponding to mini-columns 20-29\n",
    "dataset['D'].dense[30:40] = 1   # Input SDR representing \"D\", corresponding to mini-columns 30-39\n",
    "dataset['E'].dense[40:50] = 1   # Input SDR representing \"E\", corresponding to mini-columns 40-49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input: A  Bits: 1111111111 0000000000 0000000000 0000000000 0000000000 \nInput: B  Bits: 0000000000 1111111111 0000000000 0000000000 0000000000 \nInput: C  Bits: 0000000000 0000000000 1111111111 0000000000 0000000000 \nInput: D  Bits: 0000000000 0000000000 0000000000 1111111111 0000000000 \nInput: E  Bits: 0000000000 0000000000 0000000000 0000000000 1111111111 \n\n"
    }
   ],
   "source": [
    "# SDR オブジェクトの高密度データをインプレースで更新したことを通知します\n",
    "for z in dataset.values():\n",
    "  z.dense = z.dense\n",
    "for inp in \"ABCDE\":\n",
    "  print(\"Input:\", inp, \" Bits:\", formatBits( dataset[inp]) )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "################################################################################\n\nこの簡単なシーケンスを学習用の一時記憶装置に送信します\n\n計算方法は、学習および/または推論の1つのステップを実行します。注意: ここでは\n我々は学習を行うだけですが、あなたは予測/推論と学習を行うことができます。\n望むならば同じステップで（オンライン学習）.\n\nInput: A\n>>> tm.compute()\nActive cells     1111111111 0000000000 0000000000 0000000000 0000000000 \nWinner cells     1111111111 0000000000 0000000000 0000000000 0000000000 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \nAnomaly 100.0 %\n\nInput: B\n>>> tm.compute()\nActive cells     0000000000 1111111111 0000000000 0000000000 0000000000 \nWinner cells     0000000000 1111111111 0000000000 0000000000 0000000000 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \nAnomaly 100.0 %\n\nInput: C\n>>> tm.compute()\nActive cells     0000000000 0000000000 1111111111 0000000000 0000000000 \nWinner cells     0000000000 0000000000 1111111111 0000000000 0000000000 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \nAnomaly 100.0 %\n\nInput: D\n>>> tm.compute()\nActive cells     0000000000 0000000000 0000000000 1111111111 0000000000 \nWinner cells     0000000000 0000000000 0000000000 1111111111 0000000000 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \nAnomaly 100.0 %\n\nInput: E\n>>> tm.compute()\nActive cells     0000000000 0000000000 0000000000 0000000000 1111111111 \nWinner cells     0000000000 0000000000 0000000000 0000000000 1111111111 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \nAnomaly 100.0 %\n\nリセットコマンドは、シーケンスが終了したことを TM に伝えます。\nはすべての状態をゼロにします。厳密には必要ではありませんが、ちょっとした\nリセットなしではもっと難しく、TMはリセットした方が学習が早い.\n\n>>> tm.reset()\n\n"
    }
   ],
   "source": [
    "print(\"################################################################################\")\n",
    "print(\"\")\n",
    "print(\"\"\"この簡単なシーケンスを学習用の一時記憶装置に送信します\"\"\")\n",
    "print(\"\"\"\n",
    "計算方法は、学習および/または推論の1つのステップを実行します。注意: ここでは\n",
    "我々は学習を行うだけですが、あなたは予測/推論と学習を行うことができます。\n",
    "望むならば同じステップで（オンライン学習）.\n",
    "\"\"\")\n",
    "for inp in \"ABCDE\": # 各文字を順番に送る\n",
    "  print(\"Input:\", inp)\n",
    "  activeColumns = dataset[inp]\n",
    "\n",
    "  print(\">>> tm.compute()\")\n",
    "  tm.compute(activeColumns, learn = True)\n",
    "\n",
    "  printStateTM(tm)\n",
    "\n",
    "print(\"\"\"リセットコマンドは、シーケンスが終了したことを TM に伝えます。\n",
    "はすべての状態をゼロにします。厳密には必要ではありませんが、ちょっとした\n",
    "リセットなしではもっと難しく、TMはリセットした方が学習が早い.\n",
    "\"\"\")\n",
    "print(\">>> tm.reset()\")\n",
    "print(\"\")\n",
    "tm.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "################################################################################\n\nベクトルの同じシーケンスを送り、次のような予測を見てください。\nテンポラリメモリを使用しています。\n以下は、アクティブセル、予測セル、アクティブセグメントをプリントアウトした\n勝者セルです。\n注目すべきは、アクティブな状態が1であるミニカラムは，現在の入力パターンのSDRと，\n予測された、次の期待パターンのSDRを表す。\n\nInput: A\n>>> tm.compute()\nActive cells     1111111111 0000000000 0000000000 0000000000 0000000000 \nWinner cells     1111111111 0000000000 0000000000 0000000000 0000000000 \nPredictive cells 0000000000 1111111111 0000000000 0000000000 0000000000 \nAnomaly 100.0 %\n\nInput: B\n>>> tm.compute()\nActive cells     0000000000 1111111111 0000000000 0000000000 0000000000 \nWinner cells     0000000000 1111111111 0000000000 0000000000 0000000000 \nPredictive cells 0000000000 0000000000 1111111111 0000000000 0000000000 \nAnomaly 0.0 %\n\nInput: C\n>>> tm.compute()\nActive cells     0000000000 0000000000 1111111111 0000000000 0000000000 \nWinner cells     0000000000 0000000000 1111111111 0000000000 0000000000 \nPredictive cells 0000000000 0000000000 0000000000 1111111111 0000000000 \nAnomaly 0.0 %\n\nInput: D\n>>> tm.compute()\nActive cells     0000000000 0000000000 0000000000 1111111111 0000000000 \nWinner cells     0000000000 0000000000 0000000000 1111111111 0000000000 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 1111111111 \nAnomaly 0.0 %\n\nInput: E\n>>> tm.compute()\nActive cells     0000000000 0000000000 0000000000 0000000000 1111111111 \nWinner cells     0000000000 0000000000 0000000000 0000000000 1111111111 \nPredictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \nAnomaly 0.0 %\n\n"
    }
   ],
   "source": [
    "print(\"################################################################################\")\n",
    "print(\"\")\n",
    "print(\"\"\"ベクトルの同じシーケンスを送り、次のような予測を見てください。\n",
    "テンポラリメモリを使用しています。\n",
    "以下は、アクティブセル、予測セル、アクティブセグメントをプリントアウトした\n",
    "勝者セルです。\n",
    "注目すべきは、アクティブな状態が1であるミニカラムは，現在の入力パターンのSDRと，\n",
    "予測された、次の期待パターンのSDRを表す。\n",
    "\"\"\")\n",
    "for inp in \"ABCDE\":\n",
    "  print(\"Input:\", inp)\n",
    "  activeColumns = dataset[inp]\n",
    "\n",
    "  print(\">>> tm.compute()\")\n",
    "  tm.compute(activeColumns, learn = False)\n",
    "\n",
    "  printStateTM(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit699883541b9c4e059768b50f67b10466"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}